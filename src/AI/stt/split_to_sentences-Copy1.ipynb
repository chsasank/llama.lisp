{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5962c34-89a4-4d6c-8799-8c70c498fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import torchaudio\n",
    "from datasets import Dataset, Audio, load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c31a28-1e50-4bd7-b983-7061b336ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kannada_asr_data_with_transcript.json' , 'r') as kadt:\n",
    "    kannada_data_unfiltered = json.load(kadt)\n",
    "    \n",
    "kannada_data = list()\n",
    "#we do this so as to remove those without any transcript\n",
    "for i in kannada_data_unfiltered:\n",
    "    if i['transcript']==None:\n",
    "        pass\n",
    "    else:\n",
    "        kannada_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14eec2db-a686-44ca-8433-bddaf72a53f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kannada_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad64e8d2-e41e-478a-834c-6e87f0a15499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_transcript(transcript):\n",
    "    transcript_filtered = [x for x in transcript if (x['text'] != '[ಸಂಗೀತ]') and (x['text'] != '[ಪ್ರಶಂಸೆ]')]\n",
    "    \n",
    "    segments = []\n",
    "    segment_sentences = []\n",
    "    \n",
    "    min_length = 20\n",
    "    max_length = 30\n",
    "    ignore_raw_segment_length = 15\n",
    "    min_sent_chars = 30\n",
    "    \n",
    "    start = transcript_filtered[0]['start']\n",
    "    sent = \"\"\n",
    "    \n",
    "    for idx in range(len(transcript_filtered) - 1):\n",
    "        current_raw_segment = transcript_filtered[idx]\n",
    "        next_raw_segment = transcript_filtered[idx + 1]\n",
    "        \n",
    "        sent = sent + \" \" + current_raw_segment['text']\n",
    "    \n",
    "        current_raw_segment_length = next_raw_segment['start'] - current_raw_segment['start']\n",
    "        end_proposal = next_raw_segment['start']    \n",
    "        if current_raw_segment_length >= ignore_raw_segment_length:\n",
    "            end_proposal = current_raw_segment['start'] + current_raw_segment['duration']\n",
    "        \n",
    "        if (end_proposal - start >= min_length):\n",
    "            end = end_proposal\n",
    "\n",
    "            # add to the segments only if there is no noise\n",
    "            if len(sent) > min_sent_chars and (end - start < max_length):\n",
    "                segments.append([start, end])\n",
    "                segment_sentences.append(sent)\n",
    "\n",
    "            sent = \"\"\n",
    "            start = end\n",
    "    \n",
    "    segments = np.array(segments)\n",
    "\n",
    "    return segments, segment_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dee59f3-1ae3-4b4e-9dd7-0c4df671a043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f4c765383f457e95d592370ef142e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#iterate through all the video_id names foe which there was transcript\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kannada_individual_json \u001b[38;5;129;01min\u001b[39;00m tqdm(kannada_data[\u001b[38;5;241m875\u001b[39m]):\n\u001b[0;32m---> 18\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m \u001b[43mkannada_individual_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscript\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m     video_id \u001b[38;5;241m=\u001b[39m kannada_individual_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m     segments, segment_sentences \u001b[38;5;241m=\u001b[39m process_transcript(transcript)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "mypath = \"/home/phoenix/llama/llama.lisp/src/AI/stt/audio_dataset_torch_audio\"\n",
    "mypath_text = \"/home/phoenix/llama/llama.lisp/src/AI/stt/text_dataset_torch_text\"\n",
    "audio_metadata =[]\n",
    "text_metadata = []\n",
    "\n",
    "uncut_audio_dir = \"/home/phoenix/llama/llama.lisp/src/AI/stt/downloads\"\n",
    "uncut_audio_file_list = [f for f in glob.glob(os.path.join(uncut_audio_dir, \"*.mp3\"))]\n",
    "\n",
    "#check if the directory to store .txt and coressponding .mp3 is present after cutting the \n",
    "if not os.path.isdir(mypath):\n",
    "    os.makedirs(mypath)\n",
    "    \n",
    "if not os.path.isdir(mypath_text):\n",
    "    os.makedirs(mypath_text)\n",
    "\n",
    "#iterate through all the video_id names foe which there was transcript\n",
    "for kannada_individual_json in tqdm(kannada_data):\n",
    "    transcript = kannada_individual_json['transcript']\n",
    "    video_id = kannada_individual_json['video'].split(\"=\")[-1]\n",
    "    segments, segment_sentences = process_transcript(transcript)\n",
    "    segment_lengths = segments[:, 1] - segments[:, 0]\n",
    "\n",
    "    #below is w.r.t to text \n",
    "    for index,content in enumerate(segment_sentences):\n",
    "        filename = os.path.join(mypath_text,f'{video_id}_{index}.txt')\n",
    "        with open(filename , 'w') as segmnt_sentn:\n",
    "            segmnt_sentn.write(content)\n",
    "\n",
    "    text_metadata.append([f'{video_id}',len(segment_sentences)])\n",
    "    with open(\"/home/phoenix/llama/llama.lisp/src/AI/stt/audio_dataset_torch_audio/audio_metadata.txt\",\"w\") as f:\n",
    "       json.dump(text_metadata,f)\n",
    "\n",
    "       #below is w.r.t audio \n",
    "    arr, sample_rate = torchaudio.load(f'downloads/{video_id}.mp3')\n",
    "    num_secs = arr.shape[1] / sample_rate\n",
    "    for index,timestamps in enumerate(segments): \n",
    "        t1 = int(timestamps[0]*sample_rate)\n",
    "        t2 = int(timestamps[1]*sample_rate)\n",
    "        data_timestamp_audio = arr[:,t1:t2+1]\n",
    "        torchaudio.save(f'{mypath}/{video_id}_{index}.mp3', data_timestamp_audio,48000)\n",
    "    \n",
    "        \n",
    "    audio_metadata.append([f'{video_id}',len(segments)])\n",
    "    with open(\"/home/phoenix/llama/llama.lisp/src/AI/stt/text_dataset_torch_text/text_metadata.txt\",\"w\") as f:\n",
    "        json.dump(audio_metadata, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bd0f0-d3d0-4884-9cff-d94b8981c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f57d25-49d9-490f-8113-803c502ee544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mypath = \"/home/phoenix/llama/llama.lisp/src/AI/stt/audio_dataset_torch_audio\"\n",
    "mypath_text = \"/home/phoenix/llama/llama.lisp/src/AI/stt/text_dataset_torch_text\"\n",
    "audio_files = glob.glob(os.path.join(mypath, \"*.mp3\"))\n",
    "audio_prompt_files = glob.glob(os.path.join(mypath_text , \"*.txt\"))\n",
    "\n",
    "audio_prompt = list()\n",
    "for file_name in audio_prompt_files:\n",
    "    with open(file_name,\"r\") as f:\n",
    "        a = f.read()\n",
    "        print(a)\n",
    "        audio_prompt.append(a)\n",
    "    print(audio_prompt)\n",
    "    \n",
    "ds = (\n",
    "    Dataset.from_dict(\n",
    "        {\n",
    "            \"audio\": audio_files,\n",
    "            \"prompt\": audio_prompt,\n",
    "            }\n",
    "        )\n",
    "        .cast_column(\"audio\", Audio())\n",
    "        .train_test_split(seed=0)\n",
    "    )\n",
    "ds.save_to_disk(\"stt_ka_dataset_kn-IN_kannada\")\n",
    "ds.push_to_hub(\"adithyal1998Bhat/stt_synthetic_kn-IN_kannada\")\n",
    "HF_dataset_name = \"adithyal1998Bhat/stt_synthetic_kn-IN_kannada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4473d76b-5937-4777-8327-e8d7b58d730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12028752\n",
      "469321910\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5723647-b573-4e71-b783-f4f6b90becb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
